{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQDu5BtldcFG"
   },
   "outputs": [],
   "source": [
    "!pip install redis faiss-cpu numpy torch transformers openai\n",
    "!sudo apt-get install redis-server\n",
    "!redis-server --daemonize yes\n",
    "!pip install langchain_community langchain_openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "At8DZDJPenTj"
   },
   "outputs": [],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_m1uFGXd3qY"
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import faiss\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Any\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import tiktoken\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17hjk8_MfdAf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2Cn3I1vcxok"
   },
   "outputs": [],
   "source": [
    "class CacheBase:\n",
    "    def __init__(self, redis_host: str = 'localhost', redis_port: int = 6379):\n",
    "        self.redis_client = redis.Redis(host=redis_host, port=redis_port)\n",
    "\n",
    "    def set(self, key: str, value: str):\n",
    "        self.redis_client.set(key, value)\n",
    "\n",
    "    def get(self, key: str) -> str:\n",
    "        return self.redis_client.get(key)\n",
    "\n",
    "    def delete(self, key: str):\n",
    "        self.redis_client.delete(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rq90B3HJl_QO"
   },
   "outputs": [],
   "source": [
    "class VectorBase:\n",
    "    def __init__(self, dimension: int):\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner product is equivalent to cosine similarity for normalized vectors\n",
    "\n",
    "    def add(self, vectors: np.ndarray):\n",
    "        self.index.add(vectors)\n",
    "\n",
    "    def search(self, query: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return self.index.search(query, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sIxojE3mCUd"
   },
   "outputs": [],
   "source": [
    "class Embedder:\n",
    "    def __init__(self, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed(self, texts: List[str]) -> np.ndarray:\n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "        return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)  # Normalize for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRdO_fJqeSPu"
   },
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-4o-mini-2024-07-18\")\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        response = self.llm.invoke(prompt).content\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90Xc66dpeabo"
   },
   "outputs": [],
   "source": [
    "class CacheManager:\n",
    "    def __init__(self, cache_base: CacheBase, vector_base: VectorBase, embedder: Embedder, df: pd.DataFrame, llm: LLM, use_df: bool = True):\n",
    "        \"\"\"\n",
    "        :param cache_base: Cache object for key-value caching\n",
    "        :param vector_base: VectorBase object for FAISS-based vector search\n",
    "        :param embedder: Embedder object for generating embeddings\n",
    "        :param df: DataFrame containing the dataset with questions and answers\n",
    "        :param llm: LLM object for generating responses when not found in cache or DataFrame\n",
    "        :param use_df: Boolean flag to decide if we should use the DataFrame for answers\n",
    "        \"\"\"\n",
    "        self.cache_base = cache_base\n",
    "        self.vector_base = vector_base\n",
    "        self.embedder = embedder\n",
    "        self.df = df  # Store DataFrame for looking up responses\n",
    "        self.use_df = use_df  # Flag to determine if we use df or LLM\n",
    "        self.llm = llm  # LLM for generating responses if not found in DataFrame\n",
    "        self.counter = 0  # Keeps track of indices for mapping queries to FAISS indices\n",
    "        self.saved_tokens = [0, 0]  # [prompt_tokens_saved, completion_tokens_saved]\n",
    "        self.tokenizer = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "    def add_to_cache(self, query: str, response: str):\n",
    "        \"\"\"Caches question1 with a corresponding response\"\"\"\n",
    "        self.cache_base.set(query, response)\n",
    "\n",
    "        embedding = self.embedder.embed([query])\n",
    "        self.vector_base.add(embedding)\n",
    "\n",
    "        self.cache_base.set(f\"faiss_index:{self.counter}\", query)\n",
    "        self.counter += 1\n",
    "\n",
    "    def get_token_count(self, text: str) -> int:\n",
    "        \"\"\"Helper method to count tokens in a text using tiktoken.\"\"\"\n",
    "        if isinstance(text, bytes):\n",
    "            text = text.decode('utf-8')\n",
    "\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        return len(tokens)\n",
    "\n",
    "    def get_response_from_df(self, query: str) -> str:\n",
    "        \"\"\"Look up the response for a given query in the DataFrame.\"\"\"\n",
    "        row = self.df[(self.df['question1'] == query) | (self.df['question2'] == query)]\n",
    "        if not row.empty:\n",
    "            return row['answer'].values[0]  # Return the answer for the matching question1\n",
    "        return None\n",
    "\n",
    "    def get_from_cache(self, query: str, similarity_threshold: float = 0.9) -> str:\n",
    "        \"\"\"Check if question2 can be matched with a cached question1 based on embeddings\"\"\"\n",
    "        query_embedding = self.embedder.embed([query])\n",
    "        distances, indices = self.vector_base.search(query_embedding, 1)\n",
    "\n",
    "        if distances[0][0] >= similarity_threshold:\n",
    "            faiss_index = indices[0][0]\n",
    "            cached_query = self.cache_base.get(f\"faiss_index:{faiss_index}\")\n",
    "\n",
    "            if cached_query:\n",
    "                cached_response = self.cache_base.get(cached_query)\n",
    "\n",
    "                query_tokens = self.get_token_count(query)\n",
    "                response_tokens = self.get_token_count(cached_response)\n",
    "\n",
    "                self.saved_tokens[0] += query_tokens\n",
    "                self.saved_tokens[1] += response_tokens\n",
    "\n",
    "                return cached_response\n",
    "        else:\n",
    "            # Look up the response in the DataFrame first\n",
    "            if self.use_df:\n",
    "                response = self.get_response_from_df(query)\n",
    "                if response:\n",
    "                    self.add_to_cache(query, response)  # Cache the result\n",
    "                    return response\n",
    "\n",
    "            # If not found in the DataFrame, use the LLM to generate the response\n",
    "            response = self.llm.generate(query)\n",
    "            print(f'query : {query} response from LLM {response}')\n",
    "            self.add_to_cache(query, response)\n",
    "            return response\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjUSfL1P95Rm",
    "outputId": "49a757e1-c813-4f3a-99cd-a107181d9758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1t0ojkPMjY1Euaz3Ve66_EVBFFazfKLeK\n",
      "To: /content/similar_quora_general_dataset_final.csv\n",
      "\r  0% 0.00/7.53M [00:00<?, ?B/s]\r 28% 2.10M/7.53M [00:00<00:00, 20.6MB/s]\r100% 7.53M/7.53M [00:00<00:00, 54.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1t0ojkPMjY1Euaz3Ve66_EVBFFazfKLeK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OgN9fMg-OsX",
    "outputId": "3ef17662-1e45-42d1-e5c6-80baa3ed3038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0.2  10000 non-null  int64 \n",
      " 1   Unnamed: 0.1  10000 non-null  int64 \n",
      " 2   Unnamed: 0    10000 non-null  int64 \n",
      " 3   id            10000 non-null  int64 \n",
      " 4   qid1          10000 non-null  int64 \n",
      " 5   qid2          10000 non-null  int64 \n",
      " 6   question1     10000 non-null  object\n",
      " 7   question2     10000 non-null  object\n",
      " 8   is_duplicate  10000 non-null  int64 \n",
      " 9   answer        10000 non-null  object\n",
      "dtypes: int64(7), object(3)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"similar_quora_general_dataset_final.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMKYLWZCbFhs",
    "outputId": "d5558261-5dd7-4a01-c333-35d01046dd9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0.2  1000 non-null   int64 \n",
      " 1   Unnamed: 0.1  1000 non-null   int64 \n",
      " 2   Unnamed: 0    1000 non-null   int64 \n",
      " 3   id            1000 non-null   int64 \n",
      " 4   qid1          1000 non-null   int64 \n",
      " 5   qid2          1000 non-null   int64 \n",
      " 6   question1     1000 non-null   object\n",
      " 7   question2     1000 non-null   object\n",
      " 8   is_duplicate  1000 non-null   int64 \n",
      " 9   answer        1000 non-null   object\n",
      "dtypes: int64(7), object(3)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.head(1000)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00N8YyNjnSoM",
    "outputId": "6ecbd6ae-8f8c-4429-86d9-bd84ed8832fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cache_base = CacheBase()\n",
    "vector_base = VectorBase(384)\n",
    "embedder = Embedder()\n",
    "llm = LLM()\n",
    "\n",
    "cache_manager = CacheManager(cache_base, vector_base, embedder, df, llm, use_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "ZSicnb4VeXhL",
    "outputId": "0557ee87-0f0f-47e5-f25d-64925d9696c5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0.2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 0,\n        \"max\": 999,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          521,\n          737,\n          740\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 0.1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 0,\n        \"max\": 999,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          521,\n          737,\n          740\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115866,\n        \"min\": 557,\n        \"max\": 404137,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          221002,\n          47424,\n          231936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115866,\n        \"min\": 557,\n        \"max\": 404137,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          221002,\n          47424,\n          231936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qid1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 226084,\n        \"min\": 1115,\n        \"max\": 789387,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          435656,\n          94422,\n          456997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qid2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 225341,\n        \"min\": 1116,\n        \"max\": 789388,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          435657,\n          94423,\n          456998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 989,\n        \"samples\": [\n          \"What is the best way to cook precooked turkey?\",\n          \"What's the best way to make money as a programmer?\",\n          \"What's the quickest and most painless way to commit suicide?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 988,\n        \"samples\": [\n          \"What is the best way to cook a precooked turkey?\",\n          \"Is marijuana more dangerous than tobacco?\",\n          \"What is the least painful and best way to commit suicide?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_duplicate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \" To \\\"commit\\\" means several different things depending on the context:\\n 1. In a relationship or personal situation, committing means making a public declaration of love or loyalty; pledging oneself. For example: \\\"I committed myself completely when I decided we should get married.\\\" 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-33322c80-0f95-4fe4-b7fb-99d623a0fcbd\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279065</td>\n",
       "      <td>279065</td>\n",
       "      <td>548630</td>\n",
       "      <td>548631</td>\n",
       "      <td>What is it like to be undergraduate students?</td>\n",
       "      <td>What is it like to be an undergraduate student?</td>\n",
       "      <td>1</td>\n",
       "      <td>Being an Undergrad student can vary greatly d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87099</td>\n",
       "      <td>87099</td>\n",
       "      <td>172963</td>\n",
       "      <td>172964</td>\n",
       "      <td>Money: What would a world without money be like?</td>\n",
       "      <td>What would the world be like if money didn't e...</td>\n",
       "      <td>1</td>\n",
       "      <td>A world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>314999</td>\n",
       "      <td>314999</td>\n",
       "      <td>618180</td>\n",
       "      <td>618181</td>\n",
       "      <td>What are some Punjabi jokes?</td>\n",
       "      <td>What are some good Punjabi jokes?</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Why don't you ever see a bald Sikh man at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>230470</td>\n",
       "      <td>230470</td>\n",
       "      <td>454154</td>\n",
       "      <td>454155</td>\n",
       "      <td>How was the International Space Station built?</td>\n",
       "      <td>How was international space station made?</td>\n",
       "      <td>1</td>\n",
       "      <td>The construction of theInternationalSpaceStat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>179067</td>\n",
       "      <td>179067</td>\n",
       "      <td>353704</td>\n",
       "      <td>353705</td>\n",
       "      <td>What are the best Skullcandy earbuds?</td>\n",
       "      <td>What are the best Skullcandy earbuds and headp...</td>\n",
       "      <td>1</td>\n",
       "      <td>The \"best\" skull candy headphones may vary de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33322c80-0f95-4fe4-b7fb-99d623a0fcbd')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-33322c80-0f95-4fe4-b7fb-99d623a0fcbd button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-33322c80-0f95-4fe4-b7fb-99d623a0fcbd');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-80f77c3b-82b5-4a16-88fe-b5d58def0c86\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80f77c3b-82b5-4a16-88fe-b5d58def0c86')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-80f77c3b-82b5-4a16-88fe-b5d58def0c86 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0      id    qid1    qid2  \\\n",
       "0             0             0      279065  279065  548630  548631   \n",
       "1             1             1       87099   87099  172963  172964   \n",
       "2             2             2      314999  314999  618180  618181   \n",
       "3             3             3      230470  230470  454154  454155   \n",
       "4             4             4      179067  179067  353704  353705   \n",
       "\n",
       "                                          question1  \\\n",
       "0     What is it like to be undergraduate students?   \n",
       "1  Money: What would a world without money be like?   \n",
       "2                      What are some Punjabi jokes?   \n",
       "3    How was the International Space Station built?   \n",
       "4             What are the best Skullcandy earbuds?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0    What is it like to be an undergraduate student?             1   \n",
       "1  What would the world be like if money didn't e...             1   \n",
       "2                  What are some good Punjabi jokes?             1   \n",
       "3          How was international space station made?             1   \n",
       "4  What are the best Skullcandy earbuds and headp...             1   \n",
       "\n",
       "                                              answer  \n",
       "0   Being an Undergrad student can vary greatly d...  \n",
       "1                                            A world  \n",
       "2   1. Why don't you ever see a bald Sikh man at ...  \n",
       "3   The construction of theInternationalSpaceStat...  \n",
       "4   The \"best\" skull candy headphones may vary de...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "4hLHhozuchIV",
    "outputId": "e72f7eca-6502-440d-ae2f-ec4bbe6d773d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 ms, sys: 3.01 ms, total: 38.4 ms\n",
      "Wall time: 38.6 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" Being an Undergrad student can vary greatly depending on the individual, their major, institution, and personal experiences. However, in general, Under grads can expect a challenging yet rewarding experience filled with academic coursework, extracurricular activities and socializing opportunities. \\nThe academic side of things typically involves taking multiple classes per semester that are related your major or area you'd also interested in exploring further . There will usually homework assignments , exams , papers that you'll need prepare for so keeping up good study habits important .\\nYou will have more freedom as an Under grad student than when studying at higher levels; however this comes along side more responsibilities such as managing time effectively between classes, studying for examinations or working part-time jobs if needed\\nMany colleges offer various clubs and organizations that allow Students  opportunity participate sports teams that align their interest  pursue hobbies  meet new people from diverse background, make new friends\\nBe sure though this freedom comes along side responsiblities such managing your finances effectively plan ahead by keeping track expenses budget accordingly\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cache_manager.get_from_cache(\"What is it like to be undergraduate students?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnjdGVtPckao",
    "outputId": "d47faac1-9991-48ad-f910-6d630b4a8c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 ms, sys: 978 µs, total: 21.7 ms\n",
      "Wall time: 24.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b\" Being an Undergrad student can vary greatly depending on the individual, their major, institution, and personal experiences. However, in general, Under grads can expect a challenging yet rewarding experience filled with academic coursework, extracurricular activities and socializing opportunities. \\nThe academic side of things typically involves taking multiple classes per semester that are related your major or area you'd also interested in exploring further . There will usually homework assignments , exams , papers that you'll need prepare for so keeping up good study habits important .\\nYou will have more freedom as an Under grad student than when studying at higher levels; however this comes along side more responsibilities such as managing time effectively between classes, studying for examinations or working part-time jobs if needed\\nMany colleges offer various clubs and organizations that allow Students  opportunity participate sports teams that align their interest  pursue hobbies  meet new people from diverse background, make new friends\\nBe sure though this freedom comes along side responsiblities such managing your finances effectively plan ahead by keeping track expenses budget accordingly\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cache_manager.get_from_cache(\"What is it like to be an undergraduate student?\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "RRFuh9w1xw0Z",
    "outputId": "a7d30d48-8dae-4d9f-9738-5e189232d199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query : What is the capital of France? response from LLM The capital of France is Paris.\n",
      "CPU times: user 70.1 ms, sys: 0 ns, total: 70.1 ms\n",
      "Wall time: 899 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cache_manager.get_from_cache(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LH3RJA1FygDD",
    "outputId": "a3cdbcb5-794c-4608-dda2-17a9916c9738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 ms, sys: 0 ns, total: 20.8 ms\n",
      "Wall time: 22 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'The capital of France is Paris.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cache_manager.get_from_cache(\"Where the capital of France is located?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4RFUtrTZ8OJ"
   },
   "outputs": [],
   "source": [
    "# Function to cache question1 with the answers (using the DataFrame)\n",
    "def cache_question1_with_answer(cache_manager, df):\n",
    "    epoch = 1\n",
    "    epoch_interval = int(df.shape[0] * 0.1)\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row['question1']\n",
    "        answer = row['answer']\n",
    "        cache_manager.add_to_cache(question, answer)\n",
    "        if (idx + 1) % epoch_interval == 0:\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            epoch += 1\n",
    "\n",
    "# Function to test question2 and compute hit ratio based on 'is_duplicate' label\n",
    "def test_question2_for_hits(cache_manager, df):\n",
    "    total_questions = len(df)\n",
    "    hit_count = 0\n",
    "    duplicate_count = 0\n",
    "    epoch = 1\n",
    "    epoch_interval = int(df.shape[0] * 0.1)\n",
    "    for idx, row in df.iterrows():\n",
    "        query = row['question2']\n",
    "        is_duplicate = row['is_duplicate']\n",
    "\n",
    "        cached_response = cache_manager.get_from_cache(query, similarity_threshold=0.9)\n",
    "\n",
    "        if cached_response:\n",
    "            if is_duplicate == 1:\n",
    "                hit_count += 1  # Correct hit for duplicate\n",
    "            duplicate_count += 1\n",
    "\n",
    "        if (idx + 1) % epoch_interval == 0:\n",
    "          print(f\"Epoch {epoch}\")\n",
    "          epoch += 1\n",
    "\n",
    "    hit_ratio = hit_count / duplicate_count if duplicate_count > 0 else 0\n",
    "    return hit_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uhIWQti_jI9",
    "outputId": "74700a11-5c40-4087-cdee-546b2b3409bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Time for question1: 215.19 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Cache question1 with 'answer' from the dataset\n",
    "start_time_question1 = time.time()\n",
    "cache_question1_with_answer(cache_manager, df)\n",
    "end_time_question1 = time.time()\n",
    "print(f\"Time for question1: {end_time_question1 - start_time_question1:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJH9theuf4Nr",
    "outputId": "d3580ff4-4724-4c45-b4c7-72955a03a79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Time for question2: 290.08 seconds\n",
      "Hit Ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test the hit ratio for question2 (check cache hits)\n",
    "start_time_question2 = time.time()\n",
    "hit_ratio = test_question2_for_hits(cache_manager, df)\n",
    "end_time_question2 = time.time()\n",
    "print(f\"Time for question2: {end_time_question2 - start_time_question2:.2f} seconds\")\n",
    "\n",
    "print(f\"Hit Ratio: {hit_ratio}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
